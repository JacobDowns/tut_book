{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Conditional Distributions \n",
    "\n",
    "Gaussian filters use statistical linearization to obtain mean and covariance estimates. As before, suppose that $x \\sim N(\\pmb{x_0}, P_x)$ and\n",
    "\\begin{equation}\n",
    "\\pmb{y} = f(\\pmb{x}) \n",
    "\\end{equation}\n",
    "where $f : \\mathbb{R}^n \\to \\mathbb{R}^m$ is a nonlinear function. According to \\cite{Sarkka2013}, in statistical linearization, one forms a linear approximation of the nonlinear transformation \n",
    "\\begin{equation}\n",
    "g(\\pmb{x}) \\approx \\pmb{b} + A \\delta \\pmb{x} = \\pmb{b} + A (\\pmb{x} - \\pmb{x_0})\n",
    "\\end{equation}\n",
    "that minimizes the mean square error\n",
    "\\begin{equation}\n",
    "\\text{MSE}(\\pmb{b}, A) = E[(f(\\pmb{x}) - \\pmb{b} -  A \\delta \\pmb{x})\\; (f(\\pmb{x}) - \\pmb{b} -  A \\delta \\pmb{x})^T].\n",
    "\\end{equation}\n",
    "Setting derivatives with respect to $A$ and $\\pmb{b}$ yields\n",
    "\\begin{equation}\n",
    "\\pmb{b} = E[f(\\pmb{x})]\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "A = E[f(\\pmb{x}) \\delta \\pmb{x}] P_x^{-1}.\n",
    "\\end{equation}\n",
    "Here  $\\pmb{b} = E[f(\\pmb{x})]$ is exactly the mean of $\\pmb{y} = f(\\pmb{x})$. The approximate covariance is given by \n",
    "\\begin{equation}\n",
    "\\begin{gathered}\n",
    "P_y = E[(f(\\pmb{x}) - E(f(\\pmb{x})) \\; (f(\\pmb{x}) - E(f(\\pmb{x}))^T] \\\\ \n",
    "\\approx A P_x A^T = E[f(\\pmb{x}) \\; \\delta \\pmb{x}^T] P_x^{-1} E[f(\\pmb{x}) \\; \\delta \\pmb{x}^T].\n",
    "\\end{gathered}\n",
    "\\end{equation}\n",
    "Note that statistical linearization involves computing expectation integrals $E[f(\\pmb{x})]$ and $E[f(\\pmb{x}) \\; \\delta \\pmb{x}^T]$ of the form discussed in the sections on [Gaussian transformations](gaussian_transformation.ipynb) and [Gaussian quadrature](gaussian_quadrature.ipynb).\n",
    "\n",
    "\n",
    "## Conditional Distribution for an Additive Transform \n",
    "\n",
    "Consider a noisy additive transform of the form \n",
    "\\begin{equation}\n",
    "\\begin{gathered}\n",
    "\\pmb{y} = f(\\pmb{x}) + \\pmb{q} \\\\\n",
    "x \\sim N(\\pmb{x_0}, P_x) \\\\\n",
    "q \\sim N(\\pmb{0}, Q)\n",
    "\\end{gathered}\n",
    "\\end{equation}\n",
    "where $\\pmb{q}$ is the measurement noise. Suppose we have some observation $\\pmb{y_0}$ and want to compute the mean and covariance of the probability distribution \n",
    "\\begin{equation}\n",
    "P( \\pmb{x} | \\pmb{y_0}).\n",
    "\\end{equation}\n",
    "Performing statistical linearization on the augmented function $\\hat{f}(\\pmb{x}) = [\\pmb{x}, f(\\pmb{x})]$ yields the following approximations for mean and covariance\n",
    "\\begin{equation}\n",
    "E[\\hat{f}(\\pmb{x})] \\approx\n",
    "\\begin{bmatrix}\n",
    "\\pmb{x_0} \\\\\n",
    "E[f(\\pmb{x})]\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\pmb{x_0} \\\\\n",
    "\\pmb{\\mu}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{gathered}\n",
    "\\text{Cov}[\\hat{f}(\\pmb{x})] \\approx\n",
    "\\begin{bmatrix}\n",
    "P_x & E[f(\\pmb{x}) \\; \\delta \\pmb{x}^T]^T \\\\\n",
    "E[f(\\pmb{x}) \\; \\delta \\pmb{x}^T] & E[f(\\pmb{x}) \\; \\delta \\pmb{x}^T] P_x^{-1} E[f(\\pmb{x}) \\; \\delta \\pmb{x}^T] + Q\n",
    "\\end{bmatrix} \\\\\n",
    "= \n",
    "\\begin{bmatrix}\n",
    " P_x & C \\\\\n",
    " C^T & S \n",
    "\\end{bmatrix}\n",
    "\\end{gathered}\n",
    "\\end{equation}\n",
    "Here, $\\mu$ is the measurement mean, and $S$ and $C$ are the measurement covariance and cross covariance respectively. Stated otherwise, statistical linearization yields a Gaussian approximation of the joint distribution \n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "\\pmb{x} \\\\\n",
    "\\pmb{y}\n",
    "\\end{bmatrix}\n",
    "\\sim \n",
    "N \\left ( \\begin{bmatrix}\n",
    "\\pmb{x_0} \\\\\n",
    "\\pmb{\\mu}\n",
    "\\end{bmatrix},  \\begin{bmatrix}\n",
    " P_x & C \\\\\n",
    " C^T & S\n",
    "\\end{bmatrix}\\right ).\n",
    "\\end{equation}\n",
    "Given tge measurement $\\pmb{y_0}$, the mean and covariance of $\\pmb{x} | \\pmb{y_0}$ can be computed from the joint distribution as follows\n",
    "\\begin{equation}\n",
    "\\pmb{x'}  \\sim N \\left ( \\pmb{x_0} + K[\\pmb{y_o} - \\pmb{\\mu}], P_x - K S K^T \\right )\n",
    "\\end{equation}\n",
    "where $K = CS^{-1}$ is the Kalman gain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "(<a id=\"cit-Sarkka2013\" href=\"#call-Sarkka2013\">Sarkka, 2013</a>) Sarkka Simo, ``_Bayesian Filtering and Smoothing_'', , vol. , number , pp. ,  2013.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mut",
   "language": "python",
   "name": ".mut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
